from data_processor import ChatDataProcessor
from hybrid_vector_store import HybridVectorStore
from llm_generator import HybridLLMGenerator
import gc
import time

class HybridHinglishChatBot:
    def __init__(self, json_file_path):
        self.json_file_path = json_file_path
        self.processor = ChatDataProcessor(json_file_path)
        self.hybrid_store = HybridVectorStore()
        self.llm = HybridLLMGenerator()
        self.setup_complete = False
        self.total_messages = 0
    
    def setup(self):
        """Smart setup - only process if not already done"""
        print("ğŸš€ Setting up HYBRID Hinglish Discord Chat Bot...")
        print("ğŸ¯ Using RRF + BM25 + Dense Embeddings for maximum accuracy!")
        print("=" * 70)
        
        # CHECK IF ALREADY SETUP
        if self.hybrid_store.is_setup_complete():
            print("ğŸ‰ EXISTING SETUP FOUND!")
            print("ğŸ“‚ Loading pre-built indices...")
            
            # Load existing BM25 index
            if self.hybrid_store.load_existing_indices():
                vector_count = self.hybrid_store.collection.count()
                bm25_count = len(self.hybrid_store.documents)
                
                print(f"âœ… Loaded existing hybrid system:")
                print(f"ğŸ“Š Vector store: {vector_count} chunks")
                print(f"ğŸ“Š BM25 index: {bm25_count} documents")
                
                self.setup_complete = True
                self.total_messages = bm25_count * 5  # Estimate
                
                print("\n" + "=" * 70)
                print("ğŸ‰ Bot ready from existing data - NO REPROCESSING NEEDED!")
                print(f"{self.hybrid_store.get_stats()}")
                print("ğŸ” Retrieval: RRF + BM25 + LaBSE Embeddings")
                print("ğŸ§  LLM: Llama 3.1 8B (Local)")
                print("=" * 70)
                return True
        
        # IF NOT SETUP, DO FULL PROCESSING
        print("ğŸ”§ No existing setup found - processing data...")
        start_time = time.time()
        
        # Process Discord data
        messages = self.processor.load_and_clean_data()
        self.total_messages = len(messages)
        
        if not messages:
            print("âŒ No messages found!")
            return False
        
        # Create chunks
        chunks = self.processor.chunk_messages(messages)
        
        if not chunks:
            print("âŒ No chunks created!")
            return False
        
        # Free memory
        del messages
        gc.collect()
        
        # Build hybrid indices (first time)
        self.hybrid_store.add_chunks(chunks)
        
        # Free memory
        del chunks
        gc.collect()
        
        setup_time = time.time() - start_time
        
        self.setup_complete = True
        print("\n" + "=" * 70)
        print("ğŸ‰ HYBRID Chat Bot setup complete!")
        print(f"â±ï¸  Setup time: {setup_time:.1f} seconds")
        print(f"ğŸ“Š Processed: {self.total_messages:,} messages")
        print(f"{self.hybrid_store.get_stats()}")
        print("ğŸ” Retrieval: RRF + BM25 + LaBSE Embeddings")
        print("ğŸ§  LLM: Llama 3.1 8B (Local)")
        print("ğŸ’¬ Optimized for: Hinglish queries like 'bhai kya discuss hua tha'")
        print("=" * 70)
        return True
    
    def ask_question(self, question, search_mode="hybrid"):
        """Ask question with hybrid retrieval"""
        if not self.setup_complete:
            return "âŒ Setup incomplete! Run setup() first."
        
        print(f"ğŸ¤” Processing: '{question}'")
        
        # Perform hybrid search
        start_search = time.time()
        results = self.hybrid_store.hybrid_search(question, n_results=4)
        search_time = time.time() - start_search
        
        if not results or not results['documents'] or not results['documents'][0]:
            return "ğŸ¤” Koi relevant conversation nahi mila bhai! Try different keywords."
        
        # Extract results
        conversation_chunks = results['documents'][0]
        chunk_metadata = results['metadatas'][0]
        
        # Generate intelligent response
        print("ğŸ§  Generating AI response...")
        start_llm = time.time()
        
        retrieval_info = f"Vector+BM25+RRF, {len(conversation_chunks)} chunks, {search_time:.2f}s search"
        response = self.llm.generate_response(
            question, 
            conversation_chunks, 
            chunk_metadata,
            retrieval_info
        )
        
        llm_time = time.time() - start_llm
        
        # Add performance stats
        performance_note = f"\n\nâš¡ *Search: {search_time:.2f}s | Generation: {llm_time:.2f}s*"
        
        return f"ğŸ¤– **AI Response (Hybrid Retrieval):**\n\n{response}{performance_note}"
    
    def get_summary(self):
        """Get conversation summary"""
        if not self.setup_complete:
            return "âŒ Setup incomplete!"
        
        # Get diverse sample using hybrid search
        sample_queries = [
            "programming discussion coding",
            "server community members", 
            "job work career discussion",
            "competitive programming contest"
        ]
        
        all_chunks = []
        for query in sample_queries:
            results = self.hybrid_store.hybrid_search(query, n_results=2)
            if results and results['documents']:
                all_chunks.extend(results['documents'][0])
        
        # Remove duplicates
        unique_chunks = list(set(all_chunks))[:8]
        
        if not unique_chunks:
            return "ğŸ¤” No conversations available for summary"
        
        print("ğŸ“ Generating summary...")
        summary = self.llm.summarize_conversations(unique_chunks, "hybrid (RRF+BM25+Embeddings)")
        
        return f"ğŸ“‹ **Community Summary (Hybrid Analysis):**\n\n{summary}"
    
    def reset_setup(self):
        """Force reset - delete all indices to reprocess"""
        import os
        import shutil
        
        files_to_remove = [
            "./setup_complete.flag",
            "./bm25_index.pkl",
            "./hybrid_chat_db"
        ]
        
        for path in files_to_remove:
            try:
                if os.path.exists(path):
                    if os.path.isdir(path):
                        shutil.rmtree(path)
                    else:
                        os.remove(path)
                    print(f"ğŸ—‘ï¸  Removed: {path}")
            except Exception as e:
                print(f"âŒ Error removing {path}: {e}")
        
        print("âœ… Setup reset complete - next run will reprocess data")
    
    def get_stats(self):
        """Get bot statistics"""
        if not self.setup_complete:
            return "âŒ Bot not ready"
        
        return f"""ğŸ“Š **Hybrid Hinglish Chat Bot Stats:**

ğŸ”¢ **Data:**
   â€¢ Messages processed: {self.total_messages:,}
   â€¢ {self.hybrid_store.get_stats()}

ğŸ” **Retrieval System:**
   â€¢ Method: RRF + BM25 + Dense Embeddings
   â€¢ Embedding Model: LaBSE (Multilingual)
   â€¢ Keyword Search: BM25 with Hinglish tokenization
   â€¢ Fusion: Reciprocal Rank Fusion (RRF)

ğŸ§  **Generation:**
   â€¢ LLM: Llama 3.1 8B (Local)
   â€¢ Context: Up to 4 conversation chunks
   â€¢ Style: Natural Hinglish responses

ğŸ¯ **Performance:**
   â€¢ âœ… Persistent storage - no reprocessing needed
   â€¢ âœ… Sub-second search + generation
   â€¢ âœ… Perfect for mixed Hindi-English queries"""

# Main execution
if __name__ == "__main__":
    # Initialize hybrid bot
    bot = HybridHinglishChatBot("channel_export.json")
    
    # Smart setup - will skip if already done
    print("Checking for existing setup...")
    if not bot.setup():
        print("âŒ Setup failed!")
        exit()
    
    # Show stats
    print(f"\n{bot.get_stats()}")
    
    # Interactive mode
    print("\n" + "="*70)
    print("ğŸ’¬ HYBRID Interactive Mode!")
    print("ğŸ¯ Ask anything in Hindi/English/Hinglish mix")
    print("ğŸ”§ Commands: 'summary', 'stats', 'reset' (force reprocess), 'quit'")
    print("="*70)
    
    while True:
        user_input = input("\nğŸ—£ï¸  You: ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'bye']:
            print("ğŸ‘‹ Bye bhai! Hybrid chat bot shutting down...")
            break
        elif user_input.lower() == 'reset':
            bot.reset_setup()
            print("ğŸ”„ Restart the bot to reprocess data from scratch")
        elif user_input.lower() in ['summary', 'summarize']:
            response = bot.get_summary()
        elif user_input.lower() in ['stats', 'statistics']:
            response = bot.get_stats()
        else:
            response = bot.ask_question(user_input)
        
        print(f"\n{response}")
